{"file":"/Users/sjoshi/test/heimdall-lite/src/utilities/splunk_util.ts","mappings":";;AAAA,mCAAgD;AAChD,6CAAqC;AACrC,uCAAiC;AACjC,+CAAqE;AA2FrE,wDAAwD;AACxD,MAAa,cAAc;IAYzB,YAAY,IAAY,EAAE,QAAgB,EAAE,QAAgB;QAC1D,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC;QACjB,IAAI,CAAC,QAAQ,GAAG,QAAQ,CAAC;QACzB,IAAI,CAAC,QAAQ,GAAG,QAAQ,CAAC;IAC3B,CAAC;IAED;;;;OAIG;IACH,KAAK,CAAC,UAAU;QACd,OAAO,KAAK,CAAC,GAAG,IAAI,CAAC,IAAI,uBAAuB,EAAE;YAChD,OAAO,EAAE;gBACP,aAAa,EAAE,IAAI,CAAC,WAAW;aAChC;YACD,MAAM,EAAE,KAAK;SACd,CAAC,CAAC,IAAI,CACL,QAAQ,CAAC,EAAE;YACT,IAAI,CAAC,QAAQ,CAAC,EAAE,EAAE;gBAChB,MAAM,aAAa,CAAC,QAAQ,CAAC,CAAC;aAC/B;QACH,CAAC,EACD,OAAO,CAAC,EAAE;YACR,MAAM,aAAa,CAAC,OAAO,CAAC,CAAC;QAC/B,CAAC,CACF,CAAC;IACJ,CAAC;IAED;;OAEG;IACH,KAAK,CAAC,oBAAoB;QACxB,uCAAuC;QACvC,IAAI,qBAAqB,GACvB,qDAAqD,CAAC;QAExD,OAAO,IAAI,CAAC,gBAAgB,CAAC,qBAAqB,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,EAAE;YAChE,8EAA8E;YAC9E,IAAI,WAAW,GAAG,MAA4B,CAAC;YAE/C,4EAA4E;YAC5E,OAAO,WAAW,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QACtC,CAAC,CAAC,CAAC;IACL,CAAC;IAED,KAAK,CAAC,oBAAoB,CACxB,cAAsB;QAEtB,kEAAkE;QAClE,IAAI,mBAAmB,GAAG,0CAA0C,cAAc,EAAE,CAAC;QACrF,OAAO,IAAI,CAAC,gBAAgB,CAAC,mBAAmB,CAAC,CAAC;IACpD,CAAC;IAED,KAAK,CAAC,aAAa,CACjB,cAAsB;QAEtB,OAAO,IAAI,CAAC,oBAAoB,CAAC,cAAc,CAAC;aAC7C,IAAI,CAAC,MAAM,CAAC,EAAE,CAAC,oBAAoB,CAAC,MAAM,CAAC,CAAC;aAC5C,IAAI,CAAC,KAAK,CAAC,EAAE;YACZ,IAAI,KAAK,CAAC,MAAM,IAAI,CAAC,EAAE;gBACrB,MAAM,eAAe,CAAC,WAAW,CAAC;aACnC;iBAAM;gBACL,OAAO,KAAK,CAAC,CAAC,CAAC,CAAC;aACjB;QACH,CAAC,CAAC;aACD,IAAI,CAAC,UAAU,CAAC,EAAE;YACjB,uFAAuF;YACvF,IAAI,MAA8B,CAAC;YACnC,IAAI;gBACF,MAAM,GAAG,gBAAK,CAAC,WAAW,CAAC,IAAI,CAAC,SAAS,CAAC,UAAU,CAAC,CAAC,CAAC;aACxD;YAAC,OAAO,CAAC,EAAE;gBACV,MAAM,eAAe,CAAC,eAAe,CAAC;aACvC;YAED,+DAA+D;YAC/D,IAAI,MAAM,CAAC,cAAc,CAAC,EAAE;gBAC1B,iBAAiB;gBACjB,IAAI,SAAS,GAAG,MAAM,CAAC,cAAc,CAAC,CAAC;gBACvC,OAAO,SAAS,CAAC;aAClB;iBAAM;gBACL,MAAM,eAAe,CAAC,eAAe,CAAC;aACvC;QACH,CAAC,CAAC,CAAC;IACP,CAAC;IAED,mFAAmF;IACnF,IAAY,WAAW;QACrB,IAAI,WAAW,GAAG,wBAAU,CAAC,IAAI,CAAC,QAAQ,EAAE,IAAI,CAAC,QAAQ,CAAC,CAAC;QAC3D,OAAO,WAAW,CAAC;IACrB,CAAC;IAED;;;OAGG;IACH,KAAK,CAAC,gBAAgB,CAAC,aAAqB;QAC1C,OAAO,IAAI,CAAC,aAAa,CAAC,aAAa,CAAC;aACrC,IAAI,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC,QAAQ,CAAC,MAAM,EAAE,GAAG,CAAC,CAAC;aAC1C,IAAI,CAAC,SAAS,CAAC,EAAE;YAChB,IAAI,SAAS,CAAC,MAAM,KAAK,QAAQ,EAAE;gBACjC,MAAM,eAAe,CAAC,YAAY,CAAC;aACpC;YAED,OAAO,IAAI,CAAC,kBAAkB,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC;QACnD,CAAC,CAAC;aACD,KAAK,CAAC,KAAK,CAAC,EAAE;YACb,MAAM,aAAa,CAAC,KAAK,CAAC,CAAC;QAC7B,CAAC,CAAC,CAAC;IACP,CAAC;IAED,yBAAyB;IACjB,KAAK,CAAC,aAAa,CAAC,aAAqB;QAC/C,OAAO,KAAK,CAAC,GAAG,IAAI,CAAC,IAAI,uBAAuB,EAAE;YAChD,MAAM,EAAE,MAAM;YACd,OAAO,EAAE,IAAI,OAAO,CAAC;gBACnB,aAAa,EAAE,IAAI,CAAC,WAAW;aAChC,CAAC;YACF,IAAI,EAAE,+BAA+B,aAAa,EAAE;SACrD,CAAC;aACC,IAAI,CAAC,QAAQ,CAAC,EAAE;YACf,IAAI,CAAC,QAAQ,CAAC,EAAE;gBAAE,MAAM,aAAa,CAAC,QAAQ,CAAC,CAAC;YAChD,OAAO,QAAQ,CAAC,IAAI,EAAE,CAAC;QACzB,CAAC,CAAC;aACD,IAAI,CAAC,IAAI,CAAC,EAAE;YACX,gBAAgB;YAChB,IAAI,GAAG,GAAG,eAAM,CAAC,IAAI,EAAE;gBACrB,OAAO,EAAE,IAAI;aACd,CAAmB,CAAC;YACrB,OAAO,GAAG,CAAC,QAAQ,CAAC,GAAG,CAAC,KAAe,CAAC;QAC1C,CAAC,CAAC,CAAC;IACP,CAAC;IAED,2CAA2C;IACnC,KAAK,CAAC,SAAS,CAAC,MAAa;QACnC,OAAO,KAAK,CAAC,GAAG,IAAI,CAAC,IAAI,yBAAyB,MAAM,EAAE,EAAE;YAC1D,MAAM,EAAE,KAAK;YACb,OAAO,EAAE,IAAI,OAAO,CAAC;gBACnB,aAAa,EAAE,IAAI,CAAC,WAAW;aAChC,CAAC;SACH,CAAC;aACC,IAAI,CAAC,QAAQ,CAAC,EAAE;YACf,IAAI,CAAC,QAAQ,CAAC,EAAE;gBAAE,MAAM,aAAa,CAAC,QAAQ,CAAC,CAAC;YAChD,OAAO,QAAQ,CAAC,IAAI,EAAE,CAAC;QACzB,CAAC,CAAC;aACD,IAAI,CAAC,IAAI,CAAC,EAAE;YACX,gBAAgB;YAChB,IAAI,GAAG,GAAG,eAAM,CAAC,IAAI,EAAE;gBACrB,OAAO,EAAE,IAAI;aACd,CAAmB,CAAC;YAErB,2DAA2D;YAC3D,IAAI,IAAI,GAAG,GAAG,CAAC,KAAK,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,OAAO,CAAC,CAAC;YAChD,IAAI,KAAyB,CAAC;YAC9B,KAAK,IAAI,CAAC,IAAI,IAAI,EAAE;gBAClB,IAAI,CAAC,CAAC,WAAW,CAAC,IAAI,KAAK,eAAe,EAAE;oBAC1C,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC;iBACjB;aACF;YAED,uBAAuB;YACvB,IAAI,CAAC,KAAK,EAAE;gBACV,6CAA6C;gBAC7C,KAAK,GAAG,QAAQ,CAAC;aAClB;YAED,+BAA+B;YAC/B,IAAI,MAAiB,CAAC;YACtB,IAAI,KAAK,IAAI,MAAM,EAAE;gBACnB,MAAM,GAAG,WAAW,CAAC;aACtB;iBAAM,IAAI,KAAK,IAAI,QAAQ,EAAE;gBAC5B,MAAM,GAAG,QAAQ,CAAC;aACnB;iBAAM;gBACL,MAAM,GAAG,SAAS,CAAC;aACpB;YAED,sBAAsB;YACtB,OAAO;gBACL,MAAM;gBACN,MAAM;aACP,CAAC;QACJ,CAAC,CAAC,CAAC;IACP,CAAC;IAED,kDAAkD;IAC1C,KAAK,CAAC,QAAQ,CAAC,MAAa,EAAE,QAAgB;QACpD,oBAAoB;QAChB,OAAO,IAAI,EAAE;YACT,mBAAmB;YACzB,IAAI,KAAK,GAAG,MAAM,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC;YACzC,IAAI,KAAK,CAAC,MAAM,KAAK,SAAS,EAAE;gBAC9B,MAAM,kBAAK,CAAC,QAAQ,CAAC,CAAC;gBACtB,SAAS;aACV;iBAAM;gBACL,OAAO,KAAK,CAAC;aACd;SACF;IACH,CAAC;IAED,gEAAgE;IACxD,KAAK,CAAC,kBAAkB,CAAC,MAAa;QAC5C,OAAO,KAAK,CACV,GAAG,IAAI,CAAC,IAAI,yBAAyB,MAAM,oCAAoC,EAC/E;YACE,OAAO,EAAE;gBACP,aAAa,EAAE,IAAI,CAAC,WAAW;aAChC;YACD,MAAM,EAAE,KAAK;SACd,CACF;aACE,IAAI,CAAC,QAAQ,CAAC,EAAE;YACf,IAAI,CAAC,QAAQ,CAAC,EAAE;gBAAE,MAAM,aAAa,CAAC,QAAQ,CAAC,CAAC;YAChD,OAAO,QAAQ,CAAC,IAAI,EAAE,CAAC;QACzB,CAAC,CAAC;aACD,IAAI,CAAC,IAAI,CAAC,EAAE;YACX,oGAAoG;YACpG,mBAAmB;YACnB,IAAI,IAAI,GAAkB,IAAI,CAAC,SAAS,CAAC,CAAC,GAAG,CAC3C,CAAC,KAAU,EAAE,EAAE,CAAC,KAAK,CAAC,IAAI,CAC3B,CAAC;YAEF,4BAA4B;YAC5B,IAAI,MAAM,GAAG,EAAsB,CAAC;YACpC,KAAK,IAAI,CAAC,IAAI,IAAI,EAAE;gBAClB,IAAI;oBACF,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,CAAmB,CAAC,CAAC;iBAC9C;gBAAC,OAAO,GAAG,EAAE;oBACZ,OAAO,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;iBACnB;aACF;YAED,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC,CAAC;IACP,CAAC;CACF;AAtPD,wCAsPC;AAED;;;;;GAKG;AACH,SAAgB,oBAAoB,CAClC,QAA0B;IAE1B,mBAAmB;IACnB,IAAI,OAAO,GAAG,sBAAQ,CAAC,QAAQ,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;IAErD,IAAI,KAAK,GAAG,sBAAQ,CAAC,OAAO,EAAE,yBAAyB,CAAC,CAAC;IAEzD,OAAO,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC;AAC9B,CAAC;AATD,oDASC;AAED;;GAEG;AACH,SAAS,yBAAyB,CAChC,aAA+B;IAE/B,8GAA8G;IAC9G,mBAAmB;IACnB,IAAI,QAAQ,GAAG,sBAAQ,CAAC,aAAa,EAAE,KAAK,CAAC,EAAE,CAAC,KAAK,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;IACpE,IAAI,WAAW,GAAG,CAAC,QAAQ,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAuB,CAAC;IACnE,IAAI,cAAc,GAAG,CAAC,QAAQ,CAAC,SAAS,CAAC,IAAI,EAAE,CAAqB,CAAC;IACrE,IAAI,cAAc,GAAG,CAAC,QAAQ,CAAC,SAAS,CAAC,IAAI,EAAE,CAAqB,CAAC;IAErE,qCAAqC;IACrC,IAAI,WAAW,CAAC,MAAM,KAAK,CAAC,EAAE;QAC5B,MAAM,IAAI,KAAK,CACb,qDAAqD,WAAW,CAAC,MAAM,EAAE,CAC1E,CAAC;KACH;IAED,cAAc;IACd,IAAI,IAAI,GAAG,WAAW,CAAC,CAAC,CAAC,CAAC;IAE1B,qCAAqC;IACrC,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,GAAG,cAAc,CAAC,CAAC;IAEtC,sDAAsD;IACtD,IAAI,oBAAoB,GAAG,sBAAQ,CACjC,cAAc,EACd,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,IAAI,CAAC,cAAc,CACjC,CAAC;IACF,KAAK,IAAI,OAAO,IAAI,cAAc,EAAE;QAClC,gEAAgE;QAChE,IAAI,GAAG,GAAG,OAAO,CAAC,IAAI,CAAC,cAAc,CAAC;QACtC,IAAI,aAAa,GAAG,oBAAoB,CAAC,GAAG,CAAC,IAAI,EAAE,CAAC;QACpD,OAAO,CAAC,QAAQ,CAAC,IAAI,CAAC,GAAG,aAAa,CAAC,CAAC;KACzC;IAED,mBAAmB;IACnB,OAAO,IAAI,CAAC;AACd,CAAC;AAED,IAAY,eAUX;AAVD,WAAY,eAAe;IACzB,iEAAU,CAAA;IACV,yDAAM,CAAA;IACN,qEAAY,CAAA;IACZ,2DAAO,CAAA;IACP,qEAAY,CAAA;IACZ,mFAAmB,CAAA;IACnB,2EAAe,CAAA;IACf,mEAAW,CAAA;IACX,qEAAY,CAAA,CAAC,WAAW;AAC1B,CAAC,EAVW,eAAe,GAAf,uBAAe,KAAf,uBAAe,QAU1B;AAED,oEAAoE;AACpE,SAAgB,aAAa,CAC3B,CAAyC;IAEzC,OAAO,CAAC,IAAI,CAAC,gCAAgC,CAAC,CAAC;IAC/C,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;IAChB,IAAI,CAAC,YAAY,SAAS,EAAE;QAC1B,OAAO,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;QAC1B,IAAI,CAAC,CAAC,OAAO,CAAC,QAAQ,CAAC,cAAc,CAAC,EAAE;YACtC,OAAO,eAAe,CAAC,UAAU,CAAC;SACnC;aAAM,IAAI,CAAC,CAAC,OAAO,CAAC,QAAQ,CAAC,iBAAiB,CAAC,EAAE;YAChD,OAAO,eAAe,CAAC,MAAM,CAAC;SAC/B;KACF;SAAM,IAAI,CAAC,YAAY,QAAQ,EAAE;QAChC,OAAO,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC;QAC7B,mCAAmC;QACnC,IAAI,QAAQ,GAAG,CAAa,CAAC;QAC7B,QAAQ,QAAQ,CAAC,MAAM,EAAE;YACvB,KAAK,GAAG,EAAE,wBAAwB;gBAChC,OAAO,eAAe,CAAC,OAAO,CAAC;YACjC,KAAK,GAAG,EAAE,iBAAiB;gBACzB,OAAO,eAAe,CAAC,YAAY,CAAC;YACtC;gBACE,OAAO,CAAC,GAAG,CAAC,6BAA6B,GAAG,QAAQ,CAAC,MAAM,CAAC,CAAC;gBAC7D,OAAO,eAAe,CAAC,YAAY,CAAC;SACvC;KACF;SAAM,IAAI,OAAO,CAAC,KAAK,OAAO,eAAe,CAAC,YAAY,EAAE;QAC3D,0CAA0C;QAC1C,OAAO,CAAC,IAAI,CAAC,iBAAiB,CAAC,CAAC;QAChC,OAAO,CAAC,CAAC;KACV;IACD,UAAU;IACV,OAAO,eAAe,CAAC,YAAY,CAAC;AACtC,CAAC;AAhCD,sCAgCC","names":[],"sources":["/Users/sjoshi/test/heimdall-lite/src/utilities/splunk_util.ts"],"sourcesContent":["import { xml2js, ElementCompact } from \"xml-js\";\nimport { delay } from \"./async_util\";\nimport { parse } from \"inspecjs\";\nimport { Hash, group_by, map_hash, basic_auth } from \"./helper_util\";\nimport { schemas_1_0 } from \"inspecjs\";\n\n// env.NODE_TLS_REJECT_UNAUTHORIZED = \"0\";\n\nexport type JobID = string;\n\n// Interfaces\n/** The parent type to other interfaces, to save duplication */\ninterface AbsMetaInfo {\n  /** The file this came from */\n  filename: string;\n\n  /** The type of the file (NOT of this event!) */\n  filetype: \"evaluation\" | \"profile\";\n\n  /** The subtype of this specific event */\n  subtype: \"header\" | \"profile\" | \"control\";\n\n  /** A randomly generated GUID capturing all of the events in this file */\n  guid: string;\n\n  /** When this event was parsed */\n  parse_time: string;\n\n  /** The schema version: */\n  hdf_splunk_schema: string;\n\n  /** The sha256 hash of the profile that is/contains this event */\n  profile_sha256: string;\n\n  /** The start time of the control in ISO format */\n  start_time: string;\n\n  /** The control ID, repeated for convenience in splunk searches */\n  control_id: string;\n}\n\n/** The meta information for an event with the \"evaluation\" subtype */\nexport interface ExecutionMetaInfo\n  extends Omit<AbsMetaInfo, \"control_id\" | \"start_time\" | \"profile_sha256\"> {\n  subtype: \"header\";\n}\n\n/** The meta information for an event with the \"profile\" subtype */\nexport interface ProfileMetaInfo\n  extends Omit<AbsMetaInfo, \"control_id\" | \"start_time\"> {\n  subtype: \"profile\";\n}\n\n/** The meta information for an event with the \"control\" subtype */\nexport interface ControlMetaInfo extends AbsMetaInfo {\n  subtype: \"control\";\n}\n\n/** This is what we expect to find in every parsed event representing an Evaluation\n * Note that Profiles will typically be initially empty\n */\nexport interface ExecutionPayload {\n  meta: ExecutionMetaInfo;\n  profiles: ProfilePayload[];\n  [x: string]: any;\n}\n\n/** This is what we expect to find in every parsed event representing a Profile.\n * Note that controls will typically be initially empty\n */\nexport interface ProfilePayload {\n  meta: ProfileMetaInfo;\n  controls: ControlPayload[];\n  [x: string]: any;\n}\n\n/** This is what we expect to find in every parsed event representing a Control */\nexport interface ControlPayload {\n  meta: ControlMetaInfo;\n  [x: string]: any;\n}\n\n// Could be any!\nexport type UnknownPayload = ExecutionPayload | ProfilePayload | ControlPayload;\n\n/* Job states */\ntype CompleteJobStatus = \"succeeded\" | \"failed\";\ntype PendingJobStatus = \"pending\"; // There are others, but we don't handle them for now\ntype JobStatus = CompleteJobStatus | PendingJobStatus;\ninterface JobState {\n  status: JobStatus;\n  job_id: JobID;\n}\n\n/** This info is used to negotiate splunk connections */\nexport class SplunkEndpoint {\n  /** The full host information, including port (typically 8089).\n   * EX: https://localhost:8089\n   */\n  host: string;\n\n  /** Username to use for authentication */\n  username: string;\n\n  /** Password to use for authentication */\n  password: string;\n\n  constructor(host: string, username: string, password: string) {\n    this.host = host;\n    this.username = username;\n    this.password = password;\n  }\n\n  /** Checks whether we're able to successfully get jobs,\n   * which indicates proper auth.\n   *\n   * Will error if we aren't\n   */\n  async check_auth(): Promise<void> {\n    return fetch(`${this.host}/services/search/jobs`, {\n      headers: {\n        Authorization: this.auth_string\n      },\n      method: \"GET\"\n    }).then(\n      response => {\n        if (!response.ok) {\n          throw process_error(response);\n        }\n      },\n      failure => {\n        throw process_error(failure);\n      }\n    );\n  }\n\n  /** Provides a list of Evaluation meta headers from recent executions.\n   * We should eventually change this to allow more specific criteria\n   */\n  async fetch_execution_list(): Promise<ExecutionMetaInfo[]> {\n    // This search lists evaluation headers\n    let get_executions_search =\n      'spath \"meta.subtype\" | search \"meta.subtype\"=header';\n\n    return this.hdf_event_search(get_executions_search).then(events => {\n      // Because we only searched for headers, we can assume these to be eval events\n      let eval_events = events as ExecutionPayload[];\n\n      // Could perhaps just return e but I'd rather people didn't screw themselves\n      return eval_events.map(e => e.meta);\n    });\n  }\n\n  async get_execution_events(\n    execution_guid: string\n  ): Promise<UnknownPayload[]> {\n    // This search, provided a guid, returns all headers for that guid\n    let specific_evaluation = `spath \"meta.guid\" | search \"meta.guid\"=${execution_guid}`;\n    return this.hdf_event_search(specific_evaluation);\n  }\n\n  async get_execution(\n    execution_guid: string\n  ): Promise<schemas_1_0.ExecJSON.Execution> {\n    return this.get_execution_events(execution_guid)\n      .then(events => consolidate_payloads(events))\n      .then(execs => {\n        if (execs.length != 1) {\n          throw SplunkErrorCode.InvalidGUID;\n        } else {\n          return execs[0];\n        }\n      })\n      .then(full_event => {\n        // This is dumb and we should make the inspecjs layer more accepting of many file types\n        let result: parse.ConversionResult;\n        try {\n          result = parse.convertFile(JSON.stringify(full_event));\n        } catch (e) {\n          throw SplunkErrorCode.SchemaViolation;\n        }\n\n        // Determine what sort of file we (hopefully) have, then add it\n        if (result[\"1_0_ExecJson\"]) {\n          // Handle as exec\n          let execution = result[\"1_0_ExecJson\"];\n          return execution;\n        } else {\n          throw SplunkErrorCode.SchemaViolation;\n        }\n      });\n  }\n\n  /** Creates a proper base64 encoded auth string, using this objects credentials. */\n  private get auth_string(): string {\n    let auth_string = basic_auth(this.username, this.password);\n    return auth_string;\n  }\n\n  /** Performs the entire process of search string -> results array\n   *  Performs no consolidation.\n   *  Assumes your search string is properly constrained to the hdf index\n   */\n  async hdf_event_search(search_string: string): Promise<UnknownPayload[]> {\n    return this.create_search(search_string)\n      .then(job_id => this.pend_job(job_id, 500))\n      .then(job_state => {\n        if (job_state.status === \"failed\") {\n          throw SplunkErrorCode.SearchFailed;\n        }\n\n        return this.get_search_results(job_state.job_id);\n      })\n      .catch(error => {\n        throw process_error(error);\n      });\n  }\n\n  /** Returns the job id */\n  private async create_search(search_string: string): Promise<JobID> {\n    return fetch(`${this.host}/services/search/jobs`, {\n      method: \"POST\",\n      headers: new Headers({\n        Authorization: this.auth_string\n      }),\n      body: `search=search index=\"hdf\" | ${search_string}`\n    })\n      .then(response => {\n        if (!response.ok) throw process_error(response);\n        return response.text();\n      })\n      .then(text => {\n        // Parse the xml\n        let xml = xml2js(text, {\n          compact: true\n        }) as ElementCompact;\n        return xml.response.sid._text as string;\n      });\n  }\n\n  /** Returns the current state of the job */\n  private async check_job(job_id: JobID): Promise<JobState> {\n    return fetch(`${this.host}/services/search/jobs/${job_id}`, {\n      method: \"GET\",\n      headers: new Headers({\n        Authorization: this.auth_string\n      })\n    })\n      .then(response => {\n        if (!response.ok) throw process_error(response);\n        return response.text();\n      })\n      .then(text => {\n        // Parse the xml\n        let xml = xml2js(text, {\n          compact: true\n        }) as ElementCompact;\n\n        // Get the keys, and find the one with name \"dispatchState\"\n        let keys = xml.entry.content[\"s:dict\"][\"s:key\"];\n        let state: string | undefined;\n        for (let k of keys) {\n          if (k._attributes.name === \"dispatchState\") {\n            state = k._text;\n          }\n        }\n\n        // Check we found state\n        if (!state) {\n          // It probably failed if we can't find it lol\n          state = \"FAILED\";\n        }\n\n        // Decide result based on state\n        let status: JobStatus;\n        if (state == \"DONE\") {\n          status = \"succeeded\";\n        } else if (state == \"FAILED\") {\n          status = \"failed\";\n        } else {\n          status = \"pending\";\n        }\n\n        // Construct the state\n        return {\n          status,\n          job_id\n        };\n      });\n  }\n\n  /** Continually checks the job until resolution */\n  private async pend_job(job_id: JobID, interval: number): Promise<JobState> {\n    /* eslint-disable */\n        while (true) {\n            /* eslint-enable */\n      let state = await this.check_job(job_id);\n      if (state.status === \"pending\") {\n        await delay(interval);\n        continue;\n      } else {\n        return state;\n      }\n    }\n  }\n\n  /** Gets the search results for a given job id, if it is done */\n  private async get_search_results(job_id: JobID): Promise<UnknownPayload[]> {\n    return fetch(\n      `${this.host}/services/search/jobs/${job_id}/results/?output_mode=json&count=0`,\n      {\n        headers: {\n          Authorization: this.auth_string\n        },\n        method: \"GET\"\n      }\n    )\n      .then(response => {\n        if (!response.ok) throw process_error(response);\n        return response.json();\n      })\n      .then(data => {\n        // We basically can't, and really shouldn't, do typescript here. Output is 50% guaranteed to be wonk\n        // Get all the raws\n        let raws: Array<string> = data[\"results\"].map(\n          (datum: any) => datum._raw\n        );\n\n        // Parse to json, and freeze\n        let parsed = [] as UnknownPayload[];\n        for (let v of raws) {\n          try {\n            parsed.push(JSON.parse(v) as UnknownPayload);\n          } catch (err) {\n            console.warn(err);\n          }\n        }\n\n        return parsed;\n      });\n  }\n}\n\n/** Given: A list of all payloads from a search,\n * Produce: A list of Evaluation payloads containing all data properly reconstructed, recursively, into a \"normal\"\n * HDF heirarchy.\n *\n * TODO: Provide a mechanism for also returning orphaned items\n */\nexport function consolidate_payloads(\n  payloads: UnknownPayload[]\n): ExecutionPayload[] {\n  // Group by exec id\n  let grouped = group_by(payloads, pl => pl.meta.guid);\n\n  let built = map_hash(grouped, consolidate_file_payloads);\n\n  return Object.values(built);\n}\n\n/** Given: A list of all payloads from a search with the same GUID\n * Produce: A single EvaluationPayload containing all of these payloads reconstructed into the expected HDF heirarchy\n */\nfunction consolidate_file_payloads(\n  file_payloads: UnknownPayload[]\n): ExecutionPayload {\n  // In the end we wish to produce a single evaluation EventPayload which in fact contains all data for the guid\n  // Group by subtype\n  let subtypes = group_by(file_payloads, event => event.meta.subtype);\n  let exec_events = (subtypes[\"header\"] || []) as ExecutionPayload[];\n  let profile_events = (subtypes[\"profile\"] || []) as ProfilePayload[];\n  let control_events = (subtypes[\"control\"] || []) as ControlPayload[];\n\n  // Verify we only have one exec event\n  if (exec_events.length !== 1) {\n    throw new Error(\n      `Incorrect # of Evaluation events. Expected 1, got ${exec_events.length}`\n    );\n  }\n\n  // Pull it out\n  let exec = exec_events[0];\n\n  // Put all the profiles into the exec\n  exec.profiles.push(...profile_events);\n\n  // Group controls, and then put them into the profiles\n  let sha_grouped_controls = group_by(\n    control_events,\n    ctrl => ctrl.meta.profile_sha256\n  );\n  for (let profile of profile_events) {\n    // Get the corresponding controls, and put them into the profile\n    let sha = profile.meta.profile_sha256;\n    let corr_controls = sha_grouped_controls[sha] || [];\n    profile.controls.push(...corr_controls);\n  }\n\n  // Spit it back out\n  return exec;\n}\n\nexport enum SplunkErrorCode {\n  BadNetwork, // Server could not be reached, either due to bad address or bad CORS\n  BadUrl, // URL poorly formed\n  PageNotFound, // Server gave error 404\n  BadAuth, // Authorization credentials are no good\n  SearchFailed, // For whatever reason, the splunk search failed\n  ConsolidationFailed, // Something went wrong during event consolidation phase\n  SchemaViolation, // The data we got out isn't valid HDF. Hope to not see this too often\n  InvalidGUID, // If the provided GUID did not match to exactly one header\n  UnknownError // No clue!\n}\n\n/** Converts Responses and Errorcodes into purely just errorcodes */\nexport function process_error(\n  r: Response | SplunkErrorCode | TypeError\n): SplunkErrorCode {\n  console.warn(\"Got error in splunk operations\");\n  console.warn(r);\n  if (r instanceof TypeError) {\n    console.warn(\"Typeerror\");\n    if (r.message.includes(\"NetworkError\")) {\n      return SplunkErrorCode.BadNetwork;\n    } else if (r.message.includes(\"not a valid URL\")) {\n      return SplunkErrorCode.BadUrl;\n    }\n  } else if (r instanceof Response) {\n    console.warn(\"Bad Response\");\n    // Based on the network code, guess\n    let response = r as Response;\n    switch (response.status) {\n      case 401: // Bad username/password\n        return SplunkErrorCode.BadAuth;\n      case 404: // URL got borked\n        return SplunkErrorCode.PageNotFound;\n      default:\n        console.log(\"Unsure how to handle error \" + response.status);\n        return SplunkErrorCode.UnknownError;\n    }\n  } else if (typeof r === typeof SplunkErrorCode.UnknownError) {\n    // It's already an error code - pass along\n    console.warn(\"SplunkErrorCode\");\n    return r;\n  }\n  // idk lol\n  return SplunkErrorCode.UnknownError;\n}\n"],"version":3}